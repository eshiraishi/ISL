{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd24e69e-708b-41d5-8d17-00117d86a693",
   "metadata": {},
   "source": [
    "# Chapter 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42211bc6-62be-43c9-837b-812bf691610a",
   "metadata": {},
   "source": [
    "> Moreover, it serves as a good jumping-oﬀ point for\n",
    "newer approaches: as we will see in later chapters, many fancy statistical\n",
    "learning approaches can be seen as generalizations or extensions of linear\n",
    "regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "984ce6fe-3636-4914-8b25-cc0cb8f49b38",
   "metadata": {},
   "source": [
    "> Here are a few important questions that we might\n",
    "seek to address:\n",
    ">\n",
    "> 1. Is there a relationship between advertising budget and sales?\n",
    "> 2. How strong is the relationship between advertising budget and sales?\n",
    "> 3. Which media are associated with sales?\n",
    "> 4. How large is the association between each medium and sales?\n",
    "> 5. How accurately can we predict future sales?\n",
    "> 6. Is the relationship linear?\n",
    "> 7. Is there synergy among the advertising media?\n",
    ">\n",
    "> It turns out that linear regression can be used to answer each of these\n",
    "questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d3a60e2-1641-4200-9ee7-701c3f9da509",
   "metadata": {},
   "source": [
    "Assumir que\n",
    "$$\n",
    "    Y \\approx \\beta_0 + \\beta_1 X\n",
    "$$\n",
    "Onde $\\approx$ significa **aproximadamente modelado como** mais que **o valor é aproximadamente igual a**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a6a768-62dd-4511-81a7-83e89c04cc2a",
   "metadata": {},
   "source": [
    "$$\n",
    "    \\hat y_i = \\hat \\beta_0 + \\hat \\beta_1x_i \\implies\n",
    "    e_i = y_i - \\hat y_i\n",
    "$$\n",
    "\n",
    "Onde $e_i$ é o i-ésimo resíduo entre os valores reais e o modelo usando os coeficientes estimados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c87c2a6-8eef-44ea-881d-f160e636de21",
   "metadata": {},
   "source": [
    "$$\n",
    "    RSS = \\sum^n_{i=1} e^2_i = \\sum^n_{i=1}(y_i - \\hat \\beta_0 - \\hat \\beta_1x_i)^2\n",
    "$$\n",
    "\n",
    "Onde RSS é a soma residual dos quadrados, uma técnica simples diretamente relacionada à aproximação do modelo aos dados. É possível provar que os valores para $\\left\\{\\hat \\beta_0, \\hat \\beta_1\\right\\}$ que otimizam RSS são\n",
    "\n",
    "$$\n",
    "    \\hat \\beta_1 = \\frac {\\sum^n_{i=1}(x_i-\\bar x)(y_i - \\bar y)}{\\sum^n_i=1(x_i-\\bar x)^2} \\\\\n",
    "    \\hat \\beta_0 = \\bar y - \\hat \\beta_1 \\bar x\n",
    "$$\n",
    "\n",
    "Essa técnica é conhecida como otimização por mínimos quadrados, onde as médias usadas nesse contexto usam a média artimética dos valores do dataset de treino.\n",
    "\n",
    "**Dúvida:** O livro afirma que a função de RSS é sempre côncava e os valores para $\\Beta = \\left\\{\\hat \\beta_0, \\hat \\beta_1\\right\\}$ acima sempre se encontram no mínimo global da função. Existe alguma afirmação que pode ser feita sobre a concavidade do RSS?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mesmo analisando $\\Beta$ obtido com um dataset que vem de uma função exata os valores nunca serão iguais aos coeficientes da função original."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se queremos estimar o valor médio ($\\mu$) da população usando uma amostra ($\\hat \\mu$) e queremos saber quão diferentes os dois valores são podemos avaliar o Erro Padrão de $\\hat \\mu = SE(\\hat \\mu)$:\n",
    "$$\n",
    "    Var(\\hat \\mu) = SE(\\mu)^2 = \\frac{\\sigma^2}n\n",
    "$$\n",
    "Essa equação também indica que quanto maior o número de exemplos (n) menor o erro padrão e é possível inferir que a proximidade entre $\\beta_0, \\beta_1$ é:\n",
    "$$\n",
    "SE(\\hat \\beta_0)^2 = \\sigma^2\\left[\\frac 1 n + \\frac{\\bar x^2}{\\sum^n_{i=1}(x_i-\\bar x)^2}\\right] \\\\ ~ \\\\\n",
    "SE(\\hat \\beta_1)^2 = \\frac{\\sigma^2}{\\sum^n_{i=1}(x_i-\\bar x)^2}\n",
    "$$\n",
    "Desde que os erros em comum para cada exemplo tenham $\\sigma^2$ iguais e não possuam correlação, o que nem sempre é verdadeiro.\n",
    "\n",
    "Essas medidas de erro podem ser usadas para definir intervalos de confiança, o que significa que há X% de probabilidade que que esse intervalo contém o valor real da predição, o que em muitos casos é o suficiente (o capítulo 3.1. tem uma explicação com mais detalhes do que isso significa)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Essa informação também pode ser usada para criar testes de hipótese. O teste de hipótese mais comum envolve a hipótese nula, ou seja:\n",
    "\n",
    "> $H_0$: Não há relação entre X e Y.\n",
    "\n",
    "Contra a hipótese alternativa:\n",
    "\n",
    "> $H_a$: Existe alguma relação entre X e Y.\n",
    "\n",
    "Isso corresponde matematicamente a testar que:\n",
    "\n",
    "$$\n",
    "H_0: \\beta_1 = 0 \\\\\n",
    "H_a: \\beta_1 \\neq 0\n",
    "$$\n",
    "\n",
    "Já que caso a hipótese nula seja verdadeira $Y = \\beta_1 + \\epsilon$ logo não depende de X.\n",
    "\n",
    "Para garantir que a hipótese nula é verdadeira é preciso determinar que $\\hat \\beta_1 \\neq 0$ é suficientemente distante de 0, para que o valor obtido nao seja todo proveniente do erro, o que depende do erro padrão ($SE(\\hat\\beta_1)$). Se esse erro for significativamente pequeno há forte evidência que há uma relação entre os dois valores, e se for grande, $\\beta_1$ precisa ser grande em valor absoluto para rejeitar a hipótese nula. Esse teste pode ser feito usando uma estatística-t:\n",
    "$$\n",
    "    t = \\frac {\\hat \\Beta_1 - 0} {SE(\\hat \\beta_1)}\n",
    "$$\n",
    "Esse valor mede o número de desvios padrão que $\\hat\\beta_1$ está de 0. Se nenhuma relação existir entre X e Y a distribuição normal de t terá n-2 graus de liberdade. Para valores maioresq ue 30 é muito próxima da distribuição normal padrão e é simples descobrir a probabilidade de observar um número igual a |t| ou maior assumindo que $\\Beta_1 = 0$, que é chamado de valor p.\n",
    "\n",
    "Valores p pequenos podem ser uma inferência que há uma associação entre o preditor e a resposta já que significa que a probabilidade daquela distribuição ser uma coincidência é muito pequena. Nesses casos a hipótese nula pode ser rejeitada. Uma regra geral é abaixo de 5% mas esse valor depende demais do contexto.\n",
    "\n",
    "**obs:** já vi muitas pessoas classificarem em dados normais outliers como tendo 2 desvios padrão ou mais de distância da média e acredito que essa regra geral veio do teste t."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c076f88",
   "metadata": {},
   "source": [
    "Todos os testes acima são feitos para ajudar a decidir se há ou não relação entre os dados mas não dizem qual modelo se adequa melhor aos dados. Geralmente para determinar isso o RSE (residual standard error) e R^2 são usados mas existem muitos outros."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e22a15d8",
   "metadata": {},
   "source": [
    "**RSE:** É uma estimativa do desvio padrão de $\\epsilon$, o erro irredutível, ou seja, representa o valor médio da diferença entre a resposta real e a verdadeira linha de regressão.\n",
    "$$\n",
    "RSE = \\sqrt{\\frac 1 {n-2}RSS} = \\sqrt{\\frac 1 {n-2}\\sum^n_{i=1}(y_i-\\hat y_i)^2} \\\\\n",
    "RSS = \\sum^n_{i=1}(y_i-\\hat y_i)^2\n",
    "$$\n",
    "RSE pode ser considerada uma medida absoluta da falta de ajuste do modelo (minimizável) e é medido nas unidades de Y."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16633c7a",
   "metadata": {},
   "source": [
    "**$R^2$:** É uma proporção da variância explicada pelo modelo independentemente da escala de Y.\n",
    "$$\n",
    "R^2 = \\frac{TSS - RSS}{TSS} = 1-\\frac {RSS} {TSS} \\\\ ~ \\\\\n",
    "TSS = \\sum(y_i-\\bar y)^2\n",
    "$$\n",
    "TSS pode ser interpretado como a variância total na resposta antes da regressão ser treinada.\n",
    "\n",
    "RSS pode ser interpretado como a variabilidade que não foi explicada após treinar a regressão, logo TSS - RSS é a quantidade de veriabilidade na resposta que foi explicada e $R^2$ a proporção entre os dois valores (maximizável). \n",
    "\n",
    "Uma vantagem do $R^2$ é que esse valor é inerentemente mais interpretável mas em muitos contextos trazer explicabilidade para um modelo não é viável. Em geral $R^2$ é uma métrica mais útil quando as relações dos dados são interpretáveis / possuem insights mais claros. Frequentemente bons modelos de predição não possuem bom $R^2$ mesmo que possuam bom desempenho na realidade.\n",
    "\n",
    "Essa métrica pode ser tratada como uma medida da linearidade da relação entre X e Y, bem como a medida de correlação descrita antes.\n",
    "\n",
    "**OBS:** Qual a diferença dessa correlação para Pearson / Spearman / etc.?\n",
    "\n",
    "É possível demonstrar que em contextos de regressão linear simplesos dois valores são iguais, mas em contextos de regressão linear múltipla essa relação não é necessariamente verdadeira e R^2 descreve a correlação melhor que a função $Cor(X, Y)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35f6d25",
   "metadata": {},
   "source": [
    "Uma regressão linear múltipla é descrita por:\n",
    "$$\n",
    "Y = \\beta_0 + \\beta_1X_1 + \\beta_2X_2 + \\cdots + \\beta_pX_p + \\epsilon\n",
    "$$\n",
    "Os coeficientes podem ser otimizados minimizando a soma dos quadrados residuais:\n",
    "$$\n",
    "RSS = \\sum^n_{i=1}(y_i-\\hat y_i)^2\n",
    "$$\n",
    "Uma dificuldade em regressões múltiplas é interpretar a diferença entre correlação e causalidade.\n",
    "\n",
    "> When we perform multiple linear regression, we usually are interested in answering a few important questions.\n",
    "> 1. Is at least one of the predictors X1, X2,...,Xp useful in predicting the response?\n",
    "> 2. Do all the predictors help to explain Y , or is only a subset of the predictors useful?\n",
    "> 3. How well does the model fit the data?\n",
    "> 4. Given a set of predictor values, what response value should we predict, and how accurate is our prediction?\n",
    "\n",
    "1. A primeira pergunta pode ser respondida fazendo um teste de hipótese através da estatística F:\n",
    "$$\n",
    "    F = \\frac{\\frac{TSS - RSS} p}{\\frac {RSS}{n-p-1}} \\\\\n",
    "    TSS = \\sum{y_i - \\bar y}^2 \\\\\n",
    "    RSS = \\sum{y_i - \\hat y_i}^2\n",
    "$$\n",
    "É possível demonstrar que caso a hipótese nula seja falsa, o numerador é $\\sigma^2$ e no caso de ser verdadeira, o denominador será $\\sigma^2$\n",
    "Se a hipótese nula for verdadeira a estatística F terá valor próximo de 1 e caso contrário será distante de 1.\n",
    "\n",
    "2. Existem diversas formas de determinar as melhores variáveis independentes, entre elas:\n",
    "* *Forward Selection*: começa com um modelo sem preditores. Treina regressões lineares independentes e soma as regressões até achar a combinação com menor RSS e repete o processo até que uma regra seja atingida.\n",
    "* *Backward Selection\": começa considerando todas as variáveis, remove a variável com maior valor p e treina novamente até que uma regra seja atingida.\n",
    "* *Mixed Selection*: Funciona igual ao *forward selection* mas só adiciona as variáveis se o valor p está abaixo de um certo valor. Funciona melhor que o primeiro caso quando existem mais variáveis que entradas (exemplo: imagens).\n",
    "\n",
    "3. Algumas métricas de ajuste para regressões lineares múltiplas são enviesadas. Em especial o $R^2$ sem ajustes tende a priorizar modelos com muitas variáveis para aumentar a variância explicada, causando *overfitting*.\n",
    "\n",
    "Para usar o RSE corretamente é necessário usar sua forma generalizada para que mais variáveis sejam consideradas apenas quando o RSS diminui significativamente:\n",
    "$$\n",
    "    RSE = \\sqrt{\\frac 1 {n-p-1} \\cdot RSS}\n",
    "$$\n",
    "\n",
    "4. A forma mais confiável de aumentar a garantia nos resultados é considerar um intervalo de confiança para as predições."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d1d177e",
   "metadata": {},
   "source": [
    "Outras considerações:\n",
    "* Variáveis qualitativas:\n",
    "    * Se possuem apenas dois estados podem ser transformadas em variáveis *dummy* para serem tratadas como quantitativas.\n",
    "    * Se possui mais de dois estados é preciso criar uma variável nova para cada estado possível.\n",
    "    * Em ambos os casos nesse contexto essa separação para descartar variáveis dummy com valor p alto.\n",
    "* Funções não lineares como Funções aditivas ($y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2$) e funções polinomiais:\n",
    "    * Esses termos podem ser tratados como atributos novos ($x_3 = x_1 x_2, x_4 = x1^2, \\cdots$) e treinados como uma regressão linear, mas é importante verificar as correlações para evitar *overfitting*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e30e97",
   "metadata": {},
   "source": [
    "Problemas:\n",
    "* Baixa linearidade dos dados:\n",
    "    * Em certos casos é possível determinar a não linearidade dos dados usando residual plots (um gráfico de dispersão de um preditor (ou o valor predito) pelo erro do modelo para cada item).\n",
    "* Modelos lineares precisam assumir que os erros não possuem correlação (como acontece frequentemente em séries temporais), logo quando isso não é verdade é necessário usar outro tipo de abordagem.\n",
    "* Modelos lineares precisam assumir que a variância do erro sempre será igual a $\\sigma^2$. A falta desse comportamento pode ser identificada por um afunilamento no gráfico residual. Existem abordagens que funcionam melhor nesse tipo de situação, como os mínimos quadrados ponderados.\n",
    "* Outliers podem ser um problema dependendo do contexto, mas também podem ser difíceis de separar dos dados corretos. Uma forma de encontrá-los é computar e visualizar os resíduos studentizados.\n",
    "* Leverage: é o impacto que cada entrada terá durante o treinamento. Isso é perigoso se os dados são outliers.\n",
    "$$\n",
    "    h_i = \\frac 1 n + \\frac{(x_i - \\bar x)^2}{\\sum^n_{i'=1}(x_{i'}-\\bar x)^2}\n",
    "$$\n",
    "* Colinearidade: variáveis que tem forte correlação entre si mas não necessariamente com a variável preditora podem afetam fortemente a performance do modelo.\n",
    "    * Em casos simples é possível determinar colinearidade e escolher as variáveis corretas usando uma matriz de correlação.\n",
    "        * Em casos de multicolinearidade (quando uma variável independente tem forte correlação com mais de uma variável independente mas não com a variável que queremos predizer) isso não é possível mas é possível determinar o fator de inflação da variância (VIF), que é a proporção da variância dos coeficientes preditos no final pela variância desse termo ajustado sozinho (o que isso significa?).\n",
    "        $$\n",
    "            VIF(\\hat \\beta_j) = \\frac 1 {1 - R^2_{X_j | X_{-j}}} \\\\\n",
    "            R^2_{X_j | X_{-j}}: R^2 \\text{ em uma regressão usando todas as variáveis}\n",
    "        $$\n",
    "        * Regra geral: esse valor varia de 1 (não há colinearidade) a 5-10 (colinearidade problemática)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e46ba7f9",
   "metadata": {},
   "source": [
    "Regressão usando KNN:\n",
    "\n",
    "* **Vantagens**: não afirma nada sobre a linearidade da função e se ajusta às complexidades dos dados muito bem quando existem grandes volumes de dados.\n",
    "* **Desvantagens**: Casos seja treinada com poucos exemplos pode sofrer variância muito alta.\n",
    "\n",
    "$$\n",
    "    \\hat f(x_0) = \\frac 1 K \\sum_{x_i \\in N_0} y_i \\\\\n",
    "    N_0: \\text{conjunto com os K exemplos de treino mais proximos de }x_0\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b410609",
   "metadata": {},
   "source": [
    "## Laboratório\n",
    "\n",
    "**TODO:**\n",
    "* Fazer TTS do dataset\n",
    "* Verificar as métricas (RSE, R2, residual, etc.)\n",
    "* Repetir para regressão múltipla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d66dc466",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b0f0acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>479</th>\n",
       "      <td>10.23300</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.614</td>\n",
       "      <td>6.185</td>\n",
       "      <td>96.7</td>\n",
       "      <td>2.1705</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.2</td>\n",
       "      <td>18.03</td>\n",
       "      <td>14.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>0.10000</td>\n",
       "      <td>34.0</td>\n",
       "      <td>6.09</td>\n",
       "      <td>0</td>\n",
       "      <td>0.433</td>\n",
       "      <td>6.982</td>\n",
       "      <td>17.7</td>\n",
       "      <td>5.4917</td>\n",
       "      <td>7</td>\n",
       "      <td>329</td>\n",
       "      <td>16.1</td>\n",
       "      <td>4.86</td>\n",
       "      <td>33.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>4.42228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.584</td>\n",
       "      <td>6.003</td>\n",
       "      <td>94.5</td>\n",
       "      <td>2.5403</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.2</td>\n",
       "      <td>21.32</td>\n",
       "      <td>19.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0.01870</td>\n",
       "      <td>85.0</td>\n",
       "      <td>4.15</td>\n",
       "      <td>0</td>\n",
       "      <td>0.429</td>\n",
       "      <td>6.516</td>\n",
       "      <td>27.7</td>\n",
       "      <td>8.5353</td>\n",
       "      <td>4</td>\n",
       "      <td>351</td>\n",
       "      <td>17.9</td>\n",
       "      <td>6.36</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>2.24236</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.58</td>\n",
       "      <td>0</td>\n",
       "      <td>0.605</td>\n",
       "      <td>5.854</td>\n",
       "      <td>91.8</td>\n",
       "      <td>2.4220</td>\n",
       "      <td>5</td>\n",
       "      <td>403</td>\n",
       "      <td>14.7</td>\n",
       "      <td>11.64</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>0.01096</td>\n",
       "      <td>55.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>0</td>\n",
       "      <td>0.389</td>\n",
       "      <td>6.453</td>\n",
       "      <td>31.9</td>\n",
       "      <td>7.3073</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>15.3</td>\n",
       "      <td>8.23</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>0.05372</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.92</td>\n",
       "      <td>0</td>\n",
       "      <td>0.437</td>\n",
       "      <td>6.549</td>\n",
       "      <td>51.0</td>\n",
       "      <td>5.9604</td>\n",
       "      <td>4</td>\n",
       "      <td>289</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.39</td>\n",
       "      <td>27.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>459</th>\n",
       "      <td>7.75223</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0.713</td>\n",
       "      <td>6.301</td>\n",
       "      <td>83.7</td>\n",
       "      <td>2.7831</td>\n",
       "      <td>24</td>\n",
       "      <td>666</td>\n",
       "      <td>20.2</td>\n",
       "      <td>16.23</td>\n",
       "      <td>14.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0.07978</td>\n",
       "      <td>40.0</td>\n",
       "      <td>6.41</td>\n",
       "      <td>0</td>\n",
       "      <td>0.447</td>\n",
       "      <td>6.482</td>\n",
       "      <td>32.1</td>\n",
       "      <td>4.1403</td>\n",
       "      <td>4</td>\n",
       "      <td>254</td>\n",
       "      <td>17.6</td>\n",
       "      <td>7.19</td>\n",
       "      <td>29.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.14030</td>\n",
       "      <td>22.0</td>\n",
       "      <td>5.86</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431</td>\n",
       "      <td>6.487</td>\n",
       "      <td>13.0</td>\n",
       "      <td>7.3967</td>\n",
       "      <td>7</td>\n",
       "      <td>330</td>\n",
       "      <td>19.1</td>\n",
       "      <td>5.90</td>\n",
       "      <td>24.4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         crim    zn  indus  chas    nox     rm   age     dis  rad  tax  \\\n",
       "479  10.23300   0.0  18.10     0  0.614  6.185  96.7  2.1705   24  666   \n",
       "304   0.10000  34.0   6.09     0  0.433  6.982  17.7  5.4917    7  329   \n",
       "468   4.42228   0.0  18.10     0  0.584  6.003  94.5  2.5403   24  666   \n",
       "348   0.01870  85.0   4.15     0  0.429  6.516  27.7  8.5353    4  351   \n",
       "165   2.24236   0.0  19.58     0  0.605  5.854  91.8  2.4220    5  403   \n",
       "286   0.01096  55.0   2.25     0  0.389  6.453  31.9  7.3073    1  300   \n",
       "297   0.05372   0.0  13.92     0  0.437  6.549  51.0  5.9604    4  289   \n",
       "459   7.75223   0.0  18.10     0  0.713  6.301  83.7  2.7831   24  666   \n",
       "279   0.07978  40.0   6.41     0  0.447  6.482  32.1  4.1403    4  254   \n",
       "251   0.14030  22.0   5.86     0  0.431  6.487  13.0  7.3967    7  330   \n",
       "\n",
       "     ptratio  lstat  medv  \n",
       "479     20.2  18.03  14.6  \n",
       "304     16.1   4.86  33.1  \n",
       "468     20.2  21.32  19.1  \n",
       "348     17.9   6.36  23.1  \n",
       "165     14.7  11.64  22.7  \n",
       "286     15.3   8.23  22.0  \n",
       "297     16.0   7.39  27.1  \n",
       "459     20.2  16.23  14.9  \n",
       "279     17.6   7.19  29.1  \n",
       "251     19.1   5.90  24.4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../datasets/Boston.csv', index_col=0)\n",
    "df.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3b72c187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = df['lstat']\n",
    "y_train = df['medv']\n",
    "linearRegression = LinearRegression()\n",
    "linearRegression.fit(X_train.values.reshape(-1,1), y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b617f6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='lstat', ylabel='medv'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.regplot(data=df[['lstat', 'medv']], x='lstat', y='medv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f591f471",
   "metadata": {},
   "source": [
    "## Exercícios"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db67b24",
   "metadata": {},
   "source": [
    "### Conceituais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69b9c3e6",
   "metadata": {},
   "source": [
    "**1. Describe the null hypotheses to which the p-values given in Table 3.4\n",
    "correspond. Explain what conclusions you can draw based on these\n",
    "p-values. Your explanation should be phrased in terms of sales, TV,\n",
    "radio, and newspaper, rather than in terms of the coefficients of the\n",
    "linear model.**\n",
    "\n",
    "As hipóteses nulas nesse caso consideram que o coeficiente numérico para `Intercept, TV, radio, newspaper` é nulo, ou seja, existem fortes evidências que qualquer correlação linear entre o valor predito e as variáveis seja coincidência. No caso o valor p de `Intercept, TV, radio` é muito pequeno e a hipótese nula pode ser desconsiderada, porém é necessário verificar a possibilidade de colinearidade entre esses valores. `Newspaper` possui um valor p muito alto e a hipótese nula não pode ser descartada."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4be5a902",
   "metadata": {},
   "source": [
    "**2. Carefully explain the differences between the KNN classifier and KNN\n",
    "regression methods.**\n",
    "\n",
    "Um classificador KNN prediz que a classe para os dados escolhidos será a classe mais frequente entre os K exemplos de treino mais próximos desses dados.\n",
    "\n",
    "Um regressor KNN prediz que o valor estimado para os dados escolhidos será a média dos K exemplos de treino mais próximos desses dados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e51954c1",
   "metadata": {},
   "source": [
    "**3. Suppose we have a data set with five predictors, X1 = GPA, X2 = IQ, X3 = Level (1 for College and 0 for High School), X4 = Interaction between GPA and IQ, and X5 = Interaction between GPA and Level. The response is starting salary after graduation (in thousands of dollars). Suppose we use least squares to fit the model, and get βˆ0 = 50, βˆ1 = 20, βˆ2 = 0.07, βˆ3 = 35, βˆ4 = 0.01, βˆ5 = −10.**\n",
    "\n",
    "**(a) Which answer is correct, and why?**\n",
    "\n",
    "**i. For a fixed value of IQ and GPA, high school graduates earn more, on average, than college graduates.**\n",
    "\n",
    "Falso.\n",
    "\n",
    "**ii. For a fixed value of IQ and GPA, college graduates earn more, on average, than high school graduates.**\n",
    "\n",
    "Verdadeiro, já que $\\beta_3$ possui um coeficiente positivo alto.\n",
    "\n",
    "**iii. For a fixed value of IQ and GPA, high school graduates earn more, on average, than college graduates provided that the GPA is high enough.**\n",
    "\n",
    "Verdadeiro, já que $\\beta_1$ possui um coeficiente positivo alto. Porém, GPA precisa ser muito alto já que $\\beta_3$ é significativamente maior e GPA é um valor limitado.\n",
    "\n",
    "**iv. For a fixed value of IQ and GPA, college graduates earn more, on average, than high school graduates provided that the GPA is high enough.**\n",
    "\n",
    "Falso."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0230cf0f",
   "metadata": {},
   "source": [
    "**(b) Predict the salary of a college graduate with IQ of 110 and a GPA of 4.0.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2591bf5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137.1"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def salary(x1, x2, x3):\n",
    "    return 50 + 20*x1 + 0.07*x2 + 35*x3 + 0.01*x1*x2 - 10*x1*x3\n",
    "salary(4,110,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d280673",
   "metadata": {},
   "source": [
    "**(c) True or false: Since the coefficient for the GPA/IQ interaction term is very small, there is very little evidence of an interaction effect. Justify your answer.**\n",
    "\n",
    "O valor do coeficiente depende dos dados de treino e não é uma verdade absoluta sobre a relação dos dados. Para determinar o efeito de interação são mais garantidos testes de hipótese e outras métricas sobre os dados antes do treino."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e478de",
   "metadata": {},
   "source": [
    "**4. I collect a set of data (n = 100 observations) containing a single predictor and a quantitative response. I then fit a linear regression model to the data, as well as a separate cubic regression, i.e. Y = β0 + β1X + β2X2 + β3X3 + ϵ.**\n",
    "    \n",
    "**(a) Suppose that the true relationship between X and Y is linear, i.e. Y = β0 + β1X + ϵ. Consider the training residual sum of squares (RSS) for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.**\n",
    "\n",
    "A função cúbica é mais flexível que a linear e em treino tem mais potencial de minimizar o RSS que a função linear.\n",
    "\n",
    "**(b) Answer (a) using test rather than training RSS.**\n",
    "\n",
    "Falta informação sobre os dados. Nem toda relação entre duas variáveis é linear. Para maior certeza sobre a forma dos dados seria necessário a verificação entre a colinearidade e a correlação entre a função de X e Y.\n",
    "\n",
    "**(c) Suppose that the true relationship between X and Y is not linear, but we don’t know how far it is from linear. Consider the training RSS for the linear regression, and also the training RSS for the cubic regression. Would we expect one to be lower than the other, would we expect them to be the same, or is there not enough information to tell? Justify your answer.**\n",
    "\n",
    "É esperado que o RSS da função cúbica seja menor que o da função linear já que essa função é mais flexível, podendo se adequar melhor aos exemplos e obter um valor melhor para o RSS que a função linear.\n",
    "\n",
    "**(d) Answer (c) using test rather than training RSS.**\n",
    "\n",
    "É esperado que a função cúbica tenha um desempenho melhor nos testes por se adequar melhor à não linearidade da base de dados. Porém não linearidade é uma descrição muito ampla e não significa que os dados podem ser descritos por uma função cúbica."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b7fdd3",
   "metadata": {},
   "source": [
    "5. Consider the fitted values that result from performing linear regression without an intercept. In this setting, the ith fitted value takes the form\n",
    "$$\n",
    "    \\hat y_i = x_i \\hat \\beta\n",
    "$$\n",
    "\n",
    "where\n",
    "\n",
    "$$\n",
    "    \\hat \\beta = \\frac {\\sum^n_{i=1}x_iy_i}{\\sum^n_{i'=1}x^2_i}\n",
    "$$\n",
    "\n",
    "Show that we can write\n",
    "    \n",
    "$$\n",
    "    \\hat y_i = \\sum^n_{i'=1}a_{i'}y_{i'}\n",
    "$$\n",
    "\n",
    "What is $a_{i'}$?\n",
    "\n",
    "*Note: We interpret this result by saying that the fitted values from linear regression are linear combinations of the response values.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58216383",
   "metadata": {},
   "source": [
    "6. Using (3.4), argue that in the case of simple linear regression, the least squares line always passes through the point (¯x, y¯)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e67d4ff",
   "metadata": {},
   "source": [
    "7. It is claimed in the text that in the case of simple linear regression of Y onto X, the R2 statistic (3.17) is equal to the square of the correlation between X and Y (3.18). Prove that this is the case. For simplicity, you may assume that ¯x = ¯y = 0."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
